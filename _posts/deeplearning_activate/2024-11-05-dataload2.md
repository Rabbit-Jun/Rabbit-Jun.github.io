---
title: dataload2
date: 2024-11-06
categories: deeplearning
layout: post
---
# datalaod2
시간이 급박하여 제대로 공부하지 못하고 gpt가 뱉는대로 그냥 해버렸다 ㅠ.ㅜ 
시간이 날 때 다시 보면서 공부해야지 ㅠ.ㅜ  
```python
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
import torch
from torch.utils.data import Dataset

class CustomDataset(Dataset):
    def __init__(self, directory, min_length=None, scaler=None, label_encoder=None):
        self.data = []
        self.labels = []
        self.min_length = min_length
        self.scaler = scaler
        self.label_encoder = label_encoder
        self.load_files(directory)

    def load_files(self, directory):
        files = [f for f in os.listdir(directory) if f.endswith('.csv')]

        # 각 데이터셋에서 주어진 min_length에 맞춰 자르기
        for filename in files:
            df = pd.read_csv(os.path.join(directory, filename), dtype=np.float32)
            file_data = df.values.flatten()[:self.min_length]
            self.data.append(file_data)
            label = filename.split('@')[0]
            self.labels.append(label)

        self.data = np.vstack(self.data)
        # 레이블 인코딩
        if self.label_encoder:
            self.labels = self.label_encoder.transform(self.labels)
        else:
            self.labels = np.array(self.labels)


        if self.scaler:
            self.data = self.scaler.transform(self.data)


    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return torch.tensor(self.data[idx]), torch.tensor(int(self.labels[idx]))

def load_data(train_dir, test_dir, val_dir):
    # 모든 파일에서 최소 길이를 계산
    print("load_data 호출 시작")

    min_length = float('inf')
    for directory in [train_dir, test_dir, val_dir]:
        files = [f for f in os.listdir(directory) if f.endswith('.csv')]
        for filename in files:
            df = pd.read_csv(os.path.join(directory, filename), dtype=np.float32)
            min_length = min(min_length, df.values.flatten().shape[0])
    print(f"Calculated min_length: {min_length}")

    scaler = StandardScaler()
    label_encoder = LabelEncoder()

    # 훈련 데이터셋을 먼저 로드하여 레이블 인코딩 학습
    temp_train_dataset = CustomDataset(train_dir, min_length=min_length)
    label_encoder.fit(temp_train_dataset.labels)  # 레이블 인코더 학습

    # Training data
    train_dataset = CustomDataset(train_dir, min_length=min_length,  label_encoder=label_encoder)
    train_data = scaler.fit_transform(train_dataset.data)
    train_labels = train_dataset.labels

    # Validation data
    val_dataset = CustomDataset(val_dir, min_length=min_length, scaler=scaler,  label_encoder=label_encoder)
    val_data = val_dataset.data
    val_labels = val_dataset.labels

    # Test data
    test_dataset = CustomDataset(test_dir, min_length=min_length, scaler=scaler,  label_encoder=label_encoder)
    test_data = test_dataset.data
    test_labels = test_dataset.labels

    return train_data, train_labels, test_data, test_labels, val_data, val_labels
```

